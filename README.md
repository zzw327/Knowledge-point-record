# Knowledge-point-record
整理记录知识点
## 一、矩阵分解
### 1.1 分类
特征值分解  
PCA(Principal Component Analysis)分解，作用：降维、压缩。  
SVD(Singular Value Decomposition)分解，也叫奇异值分解。  
LSI(Latent Semantic Indexing)或者叫LSA(Latent Semantic Analysis)，隐语义分析分解。  
PLSA(Probabilistic Latent Semantic Analysis)，概率潜在语义分析。PLSA和LDA都是主题模型，PLSA是判别式模型。  
NMF(Non-negative Matrix Factorization)，非负矩阵分解。非负矩阵分解能够广泛应用于图像分析、文本挖掘和语言处理等领域。  
LDA(Latent Dirichlet Allocation)模型，潜在狄利克雷分配模型。LDA是一种主题模型，将文档集中每篇文档的主题以概率的形式给出，可以用于主题聚类或者文本分类，是生成式模型。LDA作为主题模型可以应用到很多领域，比如：文本情感分析、文本分类、个性化推荐、社交网络、广告预测等方面。  
MF(Matrix Factorization)模型，矩阵分解模型。矩阵分解其实可以分为很多种：  
基本矩阵分解(Basic Matrix Factorization)，basic MF分解。  
正则化矩阵分解(Regularized Matrix Factorization)。  
概率矩阵分解(Probabilistic Matrix Factorization)，PMF。  
非负矩阵分解(Non-negative Matrix Factorization)，NMF。  
正交非负矩阵分解(Orthogonal Non-negative Matrix Factorization)。  
PMF(Probabilistic Matrix Factorization)，概率矩阵分解。  
SVD++  
矩阵分解的主要应用是：降维、聚类分析、数据预处理、低维度特征学习、特征学习、推荐系统、大数据分析等  
